# Chezmoi data — non-package configuration
# Package data has been split into .chezmoidata/ directory:
#   .chezmoidata/packages.toml    — profile-based package registry
#   .chezmoidata/completions.toml — zsh completion commands
#   .chezmoidata/uv_tools.toml    — Python tools managed by uv

[claude_hooks]
  # Terminal integration hooks
  enable_kitty_tabs = false          # Update terminal tab titles with status
  enable_sketchybar = false          # Update macOS status bar

  # Logging and notification hooks
  enable_obsidian_logging = false    # Log activities to Obsidian vault
  enable_voice_notifications = false # Voice notifications for task completion

  # Development tool hooks
  enable_pre_commit_formatting = false # Run formatters on staged files

  # GitHub integration hooks
  enable_gh_context = false          # Provide GitHub context for PRs

[mcp_servers]
  # MCP Server Favorites Registry
  #
  # This section maintains a curated list of your favorite MCP servers.
  # By default, all servers are DISABLED to avoid bloating context in every repo.
  #
  # To install MCP servers for a specific project, use:
  #   - /configure:mcp command for interactive selection
  #   - MCP Management skill for automated installation based on project needs
  #
  # Note: The update-ai-tools.sh script only installs servers with enabled=true.
  # For project-specific needs, manually create .mcp.json in your project root.

  [mcp_servers.graphiti-memory]
    enabled = false
    scope = "project"
    transport = "sse"
    command = "http://localhost:8000/sse"
    args = []
    description = "Graph-based memory and knowledge management"
    category = "memory"

  [mcp_servers.vectorcode]
    enabled = false
    scope = "project"
    command = "vectorcode-mcp-server"
    args = []
    description = "Semantic code search using embeddings"
    category = "search"

  [mcp_servers.pal]
    enabled = false
    scope = "project"
    command = "uvx"
    args = ["--from", "git+https://github.com/BeehiveInnovations/pal-mcp-server.git", "pal-mcp-server"]
    description = "PAL (Provider Abstraction Layer) - Multi-provider LLM integration"
    category = "productivity"

  [mcp_servers.playwright]
    enabled = false
    scope = "project"
    command = "bunx"
    args = ["-y", "@playwright/mcp@latest"]
    description = "Browser automation and testing"
    category = "testing"

  [mcp_servers.context7]
    enabled = false
    scope = "project"
    command = "bunx"
    args = ["-y", "@upstash/context7-mcp"]
    description = "Upstash context management"
    category = "memory"

  [mcp_servers.github]
    enabled = false
    scope = "project"
    command = "go"
    args = ["run", "github.com/github/github-mcp-server/cmd/github-mcp-server@latest", "stdio"]
    description = "GitHub API integration (issues, PRs, repos)"
    category = "vcs"
    env_vars = ["GITHUB_TOKEN"]

  [mcp_servers.podio-mcp]
    enabled = false
    scope = "project"
    command = "bunx"
    args = ["https://github.com/ForumViriumHelsinki/podio-mcp"]
    description = "Podio project management integration"
    category = "productivity"
    env_vars = ["PODIO_CLIENT_ID", "PODIO_CLIENT_SECRET", "PODIO_APP_ID", "PODIO_APP_TOKEN"]

  [mcp_servers.sentry]
    enabled = false
    scope = "project"
    transport = "http"
    command = "https://mcp.sentry.dev/mcp"
    args = []
    description = "Sentry error tracking and monitoring"
    category = "monitoring"

  [mcp_servers.argocd-mcp]
    enabled = false
    scope = "project"
    command = "bunx"
    args = ["-y", "argocd-mcp@latest", "stdio"]
    description = "ArgoCD GitOps deployment management"
    category = "infrastructure"
    env_vars = ["ARGOCD_SERVER", "ARGOCD_AUTH_TOKEN"]

  [mcp_servers.serena]
    enabled = false
    scope = "project"
    command = "uvx"
    args = ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server", "--context", "claude-code", "--project", "${PWD##*/}"]
    description = "Serena - AI-powered code understanding and refactoring assistant"
    category = "ai"

  [mcp_servers.sequential-thinking]
    enabled = false
    scope = "project"
    command = "npx"
    args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]
    description = "Enhanced reasoning with sequential thinking"
    category = "ai"

  [mcp_servers.consult7]
    enabled = false
    scope = "project"
    command = "uvx"
    args = ["consult7", "${OPENROUTER_API_KEY}"]
    description = "Consult large context window LLMs via OpenRouter for analyzing extensive codebases"
    category = "ai"
    env_vars = ["OPENROUTER_API_KEY"]

[platform]
  # Platform-specific settings will be populated by templates
  cpu_cores = 0
  cpu_threads = 0
